{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6cdeb720-13ef-4a7c-a04d-7abe1337f96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import time\n",
    "import requests  \n",
    "import json  \n",
    "import openai\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from prompt_construction import *\n",
    "\n",
    "api_key = os.environ[\"OPENAI_API_KEY\"]  \n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc895f26-0060-4257-b2a0-e58b054662dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the API endpoint URL  \n",
    "def get_response_siemens_api(url, model, max_token, user_content, system_content):  \n",
    "    # Define the request headers  \n",
    "    headers = {  \n",
    "        'accept': 'application/json',  \n",
    "        'Authorization': 'Bearer {}'.format(api_key),  \n",
    "        'Content-Type': 'application/json'  \n",
    "    }  \n",
    "\n",
    "    # Define the request payload  \n",
    "    payload = {  \n",
    "        'model': model,  \n",
    "        'messages': [  \n",
    "            {'role': 'user', 'content': user_content },\n",
    "            {'role': 'system', 'content': system_content}           \n",
    "        ],  \n",
    "        'temperature': 0,  \n",
    "        'stream': False,  \n",
    "        'max_tokens': max_token          \n",
    "    }  \n",
    "      \n",
    "    # Make the POST request  \n",
    "    response = requests.post(url, headers=headers, data=json.dumps(payload))  \n",
    "      \n",
    "    # Print the response  \n",
    "    return print(response.json()[\"choices\"][0][\"message\"][\"content\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe1ed575-1edd-424b-93fc-4088a744cbf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " {The system shall refresh the display every 60 seconds: functional requirement}\n"
     ]
    }
   ],
   "source": [
    "url = 'https://api.siemens.com/llm/chat/completions'  \n",
    "model = 'mistral-7b-instruct'\n",
    "max_token = 100\n",
    "user_content = (\"Please classify the given requirement into 'functional requirement' or 'non-functional requirement'. \"\n",
    "                \"The answer should be in format {the given requirement: functional requirement or non-functional requirement}.\"\n",
    "                \"The given requirement: The system shall refresh the display every 60 seconds.\" )\n",
    "system_content = (\"You are a senior software engineer who is experienced in software requirement classification! \" )\n",
    "\n",
    "get_response_siemens_api(url, model, max_token, user_content, system_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfd9e6e-eb26-42f8-8e58-77363b45e2ff",
   "metadata": {},
   "source": [
    "# define useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b2a123dd-4d8c-47f0-b381-298130cc3aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_prompt_list(path):\n",
    "    \"\"\"read the saved list of prompts\"\"\"\n",
    "    with open(path, 'r') as file:  \n",
    "        prompt_list_read = []\n",
    "        prompt = \"\"        \n",
    "        for line in file:\n",
    "            if line == \"\\n\":\n",
    "                prompt_list_read.append(prompt)\n",
    "                prompt = \"\"\n",
    "            else:\n",
    "                prompt = prompt + \"\\n\" + line  \n",
    "\n",
    "    return prompt_list_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "29d5f0de-36b4-4174-8106-efbc53c31827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the API endpoint URL  \n",
    "def get_response_siemens_api(prompt):  \n",
    "    # Define the request headers  \n",
    "    headers = {  \n",
    "        'accept': 'application/json',  \n",
    "        'Authorization': 'Bearer {}'.format(api_key),  \n",
    "        'Content-Type': 'application/json'  \n",
    "    }  \n",
    "\n",
    "    # Define the request payload  \n",
    "    payload = {  \n",
    "        'model': 'mistral-7b-instruct',  \n",
    "        'messages': [  \n",
    "            {'role': 'user', 'content': prompt },\n",
    "            {'role': 'system', 'content': \"You are a senior software engineer who is experienced in software requirement classification! \"}           \n",
    "        ],  \n",
    "        'temperature': 0,  \n",
    "        'stream': False,  \n",
    "        'max_tokens': 6666          \n",
    "    }  \n",
    "      \n",
    "    # Make the POST request  \n",
    "    url = 'https://api.siemens.com/llm/chat/completions'  \n",
    "    response = requests.post(url, headers=headers, data=json.dumps(payload))  \n",
    "      \n",
    "    # Print the response  \n",
    "    return print(response.json()[\"choices\"][0][\"message\"][\"content\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a397408b-9701-41d8-b51d-f2d97b98384d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt_list, save_path):\n",
    "    \"\"\"load the prompt_list, get the completion from llm, and save the results.\"\"\"\n",
    "\n",
    "    start_time = time.time()  \n",
    "    \n",
    "    completion_list = []\n",
    "    for i, prompt in enumerate(prompt_list):\n",
    "        print(\"The prompt: \" + prompt + \"\\n######\")\n",
    "        completion = get_response_siemens_api(prompt)\n",
    "        print(completion)\n",
    "        completion_list.append(completion)\n",
    "        #print(i, \"th completion: \", completion)\n",
    "\n",
    "    # calculate the execution time\n",
    "    end_time = time.time()  \n",
    "    print(\"execution time: {}\".format(end_time - start_time), \"second\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24528232-7a64-4835-ba40-74f75a554eb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f1bf266a-5a96-4e97-8ecb-977cdf1a94cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prompt: \n",
      "Please classify the given software requirements into functional requirement or non-functional requirement. The answer should be one word, i.e. Functional or Non-functional\n",
      "\n",
      "Here are a few examples: \n",
      "\n",
      "'The Disputes System must allow the user to create three unique types of ticket retrieval requests. The three types of ticket retrieval requests are (1) Request for original receipt (2) Request for a copy of the receipt or (3) Request for a portfolio. A portfolio consists of documentation that would provide proof of a purchase such as the documentation that is received from a car rental agency that is more than a sales receipt.': Functional\n",
      "\n",
      "'The product shall generate a CMA report in an acceptable time.': Non-functional\n",
      "\n",
      "'The Disputes application must conform to the legal requirements as specified by Regulation E and Regulation Z that govern credit card disputes processing.': Non-functional\n",
      "\n",
      "'The System shall generate Inventory Quantity Adjustment document based on product daily sales data and product formulas.': Functional\n",
      "\n",
      "'Website shall allow the Izogn administrator to approve a review posted by a customer.': Functional\n",
      "\n",
      "'The product shall be available for use 24 hours per day 365 days per year'\n",
      "\n",
      "######\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'choices'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m prompt_list \u001b[38;5;241m=\u001b[39m read_prompt_list(path)\n\u001b[1;32m      8\u001b[0m save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 9\u001b[0m \u001b[43mget_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[69], line 9\u001b[0m, in \u001b[0;36mget_completion\u001b[0;34m(prompt_list, save_path)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, prompt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(prompt_list):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe prompt: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m prompt \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m######\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m     completion \u001b[38;5;241m=\u001b[39m \u001b[43mget_response_siemens_api\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(completion)\n\u001b[1;32m     11\u001b[0m     completion_list\u001b[38;5;241m.\u001b[39mappend(completion)\n",
      "Cell \u001b[0;32mIn[57], line 27\u001b[0m, in \u001b[0;36mget_response_siemens_api\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m     24\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mpost(url, headers\u001b[38;5;241m=\u001b[39mheaders, data\u001b[38;5;241m=\u001b[39mjson\u001b[38;5;241m.\u001b[39mdumps(payload))  \n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Print the response  \u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mprint\u001b[39m(\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mchoices\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mKeyError\u001b[0m: 'choices'"
     ]
    }
   ],
   "source": [
    "path = \"/Users/yongjiantang/Desktop/tang/code/re_genai/processed_prompts/prompt_promise_random_0_bi.txt\"\n",
    "path = \"/Users/yongjiantang/Desktop/tang/code/re_genai/processed_prompts/prompt_promise_random_5_bi.txt\"\n",
    "#path = \"/Users/yongjiantang/Desktop/tang/code/re_genai/processed_prompts/prompt_promise_random_0.txt\"\n",
    "#path = \"/Users/yongjiantang/Desktop/tang/code/re_genai/processed_prompts/prompt_promise_random_5.txt\"\n",
    "\n",
    "\n",
    "prompt_list = read_prompt_list(path)\n",
    "save_path = \"\"\n",
    "get_completion(prompt_list, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b233784-f0a0-4ba4-b3ed-6e37942d9a4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "549eeaef-8848-4c9d-8a9c-275b4037a031",
   "metadata": {},
   "source": [
    "# get completion on promise dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ceba54a-8456-4957-ad1a-b4c0ca9725b9",
   "metadata": {},
   "source": [
    "## binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef15299f-d504-4db4-bab2-4fce40713fb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0af338b-c0be-433c-9040-4fa2abb5b1b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b139d48f-3e1a-4eb2-bc9a-6d6ff2d30d44",
   "metadata": {},
   "source": [
    "## multi-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d5ab98-20e8-4999-b67f-d831d17a5e3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d2ac45f-b0fc-4136-9e26-d9c05c8dd6cd",
   "metadata": {},
   "source": [
    "# get completion on nfr dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed517d0e-a5ad-4066-9e27-a07fbbef427f",
   "metadata": {},
   "source": [
    "## multi-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d04b85-909a-4acb-a71a-acd4f19533b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
